# Advanced Monitoring and Observability Pipeline
# Automated monitoring setup, health checks, and incident management

name: Monitoring Pipeline

on:
  push:
    branches: [main]
    paths:
      - 'monitoring/**'
      - '.github/workflows/monitoring.yml'
  schedule:
    # Run monitoring checks every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of monitoring check to run'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - health
        - performance
        - alerts
        - metrics

env:
  MONITORING_NAMESPACE: monitoring
  GRAFANA_URL: https://grafana.agentic-startup.com
  PROMETHEUS_URL: https://prometheus.agentic-startup.com

jobs:
  # Health Check Validation
  health-checks:
    name: Health Check Validation
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'health' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install monitoring tools
        run: |
          pip install requests prometheus-client psutil

      - name: Check application endpoints
        run: |
          python << 'EOF'
          import requests
          import json
          import sys
          
          endpoints = [
              {"name": "Production Health", "url": "https://agentic-startup.com/health"},
              {"name": "Production API", "url": "https://agentic-startup.com/api/v1/health"},
              {"name": "Staging Health", "url": "https://staging.agentic-startup.com/health"},
              {"name": "Staging API", "url": "https://staging.agentic-startup.com/api/v1/health"}
          ]
          
          results = []
          for endpoint in endpoints:
              try:
                  response = requests.get(endpoint["url"], timeout=10)
                  status = "‚úÖ UP" if response.status_code == 200 else f"‚ùå DOWN ({response.status_code})"
                  results.append({"name": endpoint["name"], "status": status, "response_time": response.elapsed.total_seconds()})
                  print(f"{endpoint['name']}: {status} ({response.elapsed.total_seconds():.2f}s)")
              except Exception as e:
                  results.append({"name": endpoint["name"], "status": f"‚ùå ERROR ({str(e)})", "response_time": None})
                  print(f"{endpoint['name']}: ‚ùå ERROR - {str(e)}")
          
          # Save results for later use
          with open('health-check-results.json', 'w') as f:
              json.dump(results, f, indent=2)
          
          # Check if any endpoints are down
          failed_checks = [r for r in results if "‚ùå" in r["status"]]
          if failed_checks:
              print(f"üö® {len(failed_checks)} health checks failed!")
              sys.exit(1)
          else:
              print("‚úÖ All health checks passed!")
          EOF

      - name: Upload health check results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: health-check-results
          path: health-check-results.json

  # Performance Monitoring
  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'performance' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install performance monitoring tools
        run: |
          pip install requests prometheus-client psutil matplotlib

      - name: Run performance checks
        run: |
          python << 'EOF'
          import requests
          import time
          import statistics
          import json
          
          def measure_response_times(url, num_requests=10):
              response_times = []
              for i in range(num_requests):
                  start_time = time.time()
                  try:
                      response = requests.get(url, timeout=30)
                      end_time = time.time()
                      response_times.append(end_time - start_time)
                      print(f"Request {i+1}: {end_time - start_time:.3f}s (Status: {response.status_code})")
                  except Exception as e:
                      print(f"Request {i+1}: ERROR - {str(e)}")
                  time.sleep(1)
              return response_times
          
          endpoints = [
              "https://agentic-startup.com/health",
              "https://agentic-startup.com/api/v1/health"
          ]
          
          performance_results = {}
          for endpoint in endpoints:
              print(f"\nüìä Testing {endpoint}")
              response_times = measure_response_times(endpoint)
              
              if response_times:
                  avg_time = statistics.mean(response_times)
                  p95_time = sorted(response_times)[int(0.95 * len(response_times))]
                  
                  performance_results[endpoint] = {
                      "average_response_time": avg_time,
                      "p95_response_time": p95_time,
                      "min_response_time": min(response_times),
                      "max_response_time": max(response_times),
                      "total_requests": len(response_times)
                  }
                  
                  print(f"Average: {avg_time:.3f}s")
                  print(f"P95: {p95_time:.3f}s")
                  print(f"Min: {min(response_times):.3f}s")
                  print(f"Max: {max(response_times):.3f}s")
                  
                  # Alert if performance is degraded
                  if avg_time > 2.0:
                      print(f"üö® Performance alert: Average response time {avg_time:.3f}s exceeds threshold!")
                  if p95_time > 5.0:
                      print(f"üö® Performance alert: P95 response time {p95_time:.3f}s exceeds threshold!")
          
          # Save performance results
          with open('performance-results.json', 'w') as f:
              json.dump(performance_results, f, indent=2)
          EOF

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: performance-results.json

  # Metrics Collection and Validation
  metrics-validation:
    name: Metrics Collection and Validation
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'metrics' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install metrics tools
        run: |
          pip install requests prometheus-client

      - name: Validate Prometheus metrics
        run: |
          python << 'EOF'
          import requests
          import json
          
          def query_prometheus(query):
              try:
                  url = f"${{ env.PROMETHEUS_URL }}/api/v1/query"
                  params = {"query": query}
                  response = requests.get(url, params=params, timeout=10)
                  if response.status_code == 200:
                      return response.json()
                  else:
                      print(f"Prometheus query failed: {response.status_code}")
                      return None
              except Exception as e:
                  print(f"Error querying Prometheus: {str(e)}")
                  return None
          
          # Key metrics to validate
          metrics_queries = {
              "cpu_usage": "100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
              "memory_usage": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
              "http_request_rate": "rate(http_requests_total[5m])",
              "error_rate": "rate(http_requests_total{status=~\"5..\"}[5m])",
              "response_time_p95": "histogram_quantile(0.95, http_request_duration_seconds_bucket)"
          }
          
          metrics_results = {}
          for metric_name, query in metrics_queries.items():
              print(f"üìä Querying {metric_name}...")
              result = query_prometheus(query)
              if result and result.get("data", {}).get("result"):
                  metrics_results[metric_name] = result["data"]["result"]
                  print(f"‚úÖ {metric_name}: Data available")
              else:
                  metrics_results[metric_name] = None
                  print(f"‚ùå {metric_name}: No data available")
          
          # Save metrics results
          with open('metrics-results.json', 'w') as f:
              json.dump(metrics_results, f, indent=2)
          
          # Check for critical thresholds
          alerts = []
          if metrics_results.get("cpu_usage"):
              for result in metrics_results["cpu_usage"]:
                  if float(result["value"][1]) > 80:
                      alerts.append(f"High CPU usage: {result['value'][1]}%")
          
          if metrics_results.get("error_rate"):
              for result in metrics_results["error_rate"]:
                  if float(result["value"][1]) > 0.01:
                      alerts.append(f"High error rate: {result['value'][1]}")
          
          if alerts:
              print("üö® Metric alerts:")
              for alert in alerts:
                  print(f"  - {alert}")
          else:
              print("‚úÖ All metrics within normal ranges")
          EOF

      - name: Upload metrics results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: metrics-results
          path: metrics-results.json

  # Alert Rules Validation
  alert-validation:
    name: Alert Rules Validation
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'alerts' || github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate Prometheus alert rules
        run: |
          # Install promtool
          curl -LO https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz
          tar xvf prometheus-2.45.0.linux-amd64.tar.gz
          sudo mv prometheus-2.45.0.linux-amd64/promtool /usr/local/bin/

      - name: Check alert rules syntax
        run: |
          promtool check rules monitoring/alert_rules.yml

      - name: Validate alert rule coverage
        run: |
          python << 'EOF'
          import yaml
          import json
          
          # Load alert rules
          with open('monitoring/alert_rules.yml', 'r') as f:
              alert_rules = yaml.safe_load(f)
          
          # Check for required alert categories
          required_alerts = [
              "HighErrorRate",
              "HighResponseTime", 
              "HighCPUUsage",
              "HighMemoryUsage",
              "ServiceDown",
              "DatabaseConnectionFailure"
          ]
          
          found_alerts = []
          if 'groups' in alert_rules:
              for group in alert_rules['groups']:
                  if 'rules' in group:
                      for rule in group['rules']:
                          if 'alert' in rule:
                              found_alerts.append(rule['alert'])
          
          print("üìã Alert Rule Coverage:")
          coverage_results = {}
          for required_alert in required_alerts:
              if required_alert in found_alerts:
                  print(f"‚úÖ {required_alert}: Configured")
                  coverage_results[required_alert] = "configured"
              else:
                  print(f"‚ùå {required_alert}: Missing")
                  coverage_results[required_alert] = "missing"
          
          # Save coverage results
          with open('alert-coverage.json', 'w') as f:
              json.dump(coverage_results, f, indent=2)
          
          missing_alerts = [k for k, v in coverage_results.items() if v == "missing"]
          if missing_alerts:
              print(f"üö® {len(missing_alerts)} required alerts are missing!")
          else:
              print("‚úÖ All required alerts are configured")
          EOF

      - name: Upload alert validation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: alert-validation-results
          path: alert-coverage.json

  # Dashboard Validation
  dashboard-validation:
    name: Dashboard Validation
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate Grafana dashboard configuration
        run: |
          python << 'EOF'
          import yaml
          import json
          import os
          
          def validate_grafana_config():
              # Check datasources configuration
              datasources_path = 'monitoring/grafana/provisioning/datasources/prometheus.yml'
              if os.path.exists(datasources_path):
                  with open(datasources_path, 'r') as f:
                      datasources = yaml.safe_load(f)
                  print("‚úÖ Datasources configuration found")
              else:
                  print("‚ùå Datasources configuration missing")
                  return False
              
              # Check dashboards configuration
              dashboards_path = 'monitoring/grafana/provisioning/dashboards/dashboards.yml'
              if os.path.exists(dashboards_path):
                  with open(dashboards_path, 'r') as f:
                      dashboards = yaml.safe_load(f)
                  print("‚úÖ Dashboards configuration found")
              else:
                  print("‚ùå Dashboards configuration missing")
                  return False
              
              return True
          
          if validate_grafana_config():
              print("‚úÖ Grafana configuration validation passed")
          else:
              print("‚ùå Grafana configuration validation failed")
          EOF

  # Incident Response Simulation
  incident-response:
    name: Incident Response Simulation
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Simulate incident response workflow
        run: |
          echo "üö® Simulating incident response workflow..."
          
          # Create a test incident
          echo "1. Incident detected: Service response time exceeded threshold"
          echo "2. Alert triggered in monitoring system"
          echo "3. Incident ticket created automatically"
          echo "4. On-call team notified"
          echo "5. Escalation procedures initiated"
          
          # Test GitHub issue creation for incidents
          echo "Testing automated incident ticket creation..."

      - name: Create test incident issue
        uses: actions/github-script@v7
        with:
          script: |
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[TEST] Incident Response Simulation - ${new Date().toISOString()}`,
              body: `This is a test incident created by the monitoring pipeline to validate incident response automation.
              
              **Incident Details:**
              - Type: Response Time Alert
              - Severity: Medium
              - Environment: Staging
              - Timestamp: ${new Date().toISOString()}
              
              **Next Steps:**
              1. Acknowledge incident
              2. Investigate root cause
              3. Implement fix
              4. Monitor recovery
              5. Close incident
              
              This issue will be automatically closed by the monitoring pipeline.`,
              labels: ['incident', 'test', 'monitoring', 'automated']
            });
            
            console.log(`Created test incident issue #${issue.data.number}`);
            
            // Close the test issue immediately
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue.data.number,
              state: 'closed'
            });
            
            console.log(`Closed test incident issue #${issue.data.number}`);

  # Monitoring Summary Report
  monitoring-summary:
    name: Monitoring Summary Report
    runs-on: ubuntu-latest
    needs: [health-checks, performance-monitoring, metrics-validation, alert-validation, dashboard-validation, incident-response]
    if: always()
    steps:
      - name: Download all monitoring results
        uses: actions/download-artifact@v4

      - name: Generate monitoring summary
        run: |
          cat << 'EOF' > monitoring-summary.md
          # üìä Monitoring Pipeline Summary
          
          **Execution Date:** $(date)
          **Trigger:** ${{ github.event_name }}
          
          ## üè• System Health Status
          
          ### Health Checks
          - **Status:** ${{ needs.health-checks.result }}
          - **Application Endpoints:** Validated
          - **API Health:** Monitored
          
          ### Performance Monitoring
          - **Status:** ${{ needs.performance-monitoring.result }}
          - **Response Times:** Measured
          - **Performance Thresholds:** Validated
          
          ### Metrics Collection
          - **Status:** ${{ needs.metrics-validation.result }}
          - **Prometheus Metrics:** Validated
          - **Key Performance Indicators:** Monitored
          
          ### Alert Configuration
          - **Status:** ${{ needs.alert-validation.result }}
          - **Alert Rules:** Validated
          - **Coverage:** Assessed
          
          ### Dashboard Validation
          - **Status:** ${{ needs.dashboard-validation.result }}
          - **Grafana Dashboards:** Validated
          - **Visualizations:** Confirmed
          
          ### Incident Response
          - **Status:** ${{ needs.incident-response.result }}
          - **Response Workflow:** Tested
          - **Automation:** Validated
          
          ## üìà Key Metrics
          
          - **System Uptime:** Monitored continuously
          - **Error Rates:** Within acceptable thresholds
          - **Response Times:** Performance validated
          - **Resource Utilization:** Tracked and alerted
          
          ## üö® Action Items
          
          - Review any failed monitoring checks
          - Update alert thresholds if needed
          - Verify incident response procedures
          - Monitor system performance trends
          
          ---
          
          *Generated by Monitoring Pipeline - ${{ github.run_id }}*
          EOF

      - name: Upload monitoring summary
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-summary
          path: monitoring-summary.md

      - name: Create monitoring issue for failures
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Monitoring Pipeline Failures - ${new Date().toISOString().split('T')[0]}`,
              body: `The monitoring pipeline has detected issues that require attention:
              
              **Failed Checks:**
              - Health Checks: ${{ needs.health-checks.result }}
              - Performance Monitoring: ${{ needs.performance-monitoring.result }}
              - Metrics Validation: ${{ needs.metrics-validation.result }}
              - Alert Validation: ${{ needs.alert-validation.result }}
              - Dashboard Validation: ${{ needs.dashboard-validation.result }}
              - Incident Response: ${{ needs.incident-response.result }}
              
              Please investigate and resolve the issues promptly.`,
              labels: ['monitoring', 'urgent', 'automated', 'infrastructure']
            })